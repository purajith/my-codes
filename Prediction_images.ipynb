{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5308e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import libraries \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.cluster import DBSCAN  # For DBSCAN\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "139977ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Convolution2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from tf.keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25f351a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_paths=[] #List to store path of all images\n",
    "\n",
    "for dirname, _, filenames in os.walk('../Dataset/MICC-F220'):\n",
    "    for filename in filenames:\n",
    "        if '.txt' in filename:\n",
    "            continue\n",
    "        image_paths.append(os.path.join(dirname, filename))\n",
    "        \n",
    "        \n",
    "# prepare dataset\n",
    "original_images=[]\n",
    "tampered_images=[]\n",
    "x = []\n",
    "y = []\n",
    "for path in image_paths:\n",
    "    \n",
    "    if 'tamp' in path:              # As Observed from the above list tampered images name has tamp\n",
    "        img = cv2.imread(path)\n",
    "        img_resize = cv2.resize(img,(224,224))\n",
    "        img_scale = img_resize/255.0\n",
    "        x.append(img_scale)\n",
    "        y.append(0)\n",
    "\n",
    "        \n",
    "        tampered_images.append(path)\n",
    "    else:\n",
    "        img = cv2.imread(path)\n",
    "        img_resize = cv2.resize(img,(224,224))\n",
    "        img_scale = img_resize/255.0\n",
    "        x.append(img_scale)\n",
    "        y.append(1)\n",
    "        original_images.append(path)\n",
    "tampered_images.sort()\n",
    "original_images.sort()\n",
    "print(len(original_images),len(tampered_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9edff414",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(x)\n",
    "Y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12786f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape\n",
    "Y[111]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884d7c4",
   "metadata": {},
   "source": [
    "# model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the architecture of ResNet50 with ImageNet weights\n",
    "base_model = ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd91fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = ResNet50(include_top=False,input_shape=(240,240,3), pooling='avg', weights='imagenet')\n",
    "\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44a3caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Taking the output of the last convolution block in ResNet50\n",
    "x = base_model.output\n",
    " \n",
    "# Adding a Global Average Pooling layer\n",
    "x = GlobalAveragePooling2D()(x)\n",
    " \n",
    "# Adding a fully connected layer having 1024 neurons\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(240, activation='relu')(x)\n",
    "\n",
    "# Adding a fully connected layer having 2 neurons which will\n",
    "# give the probability of image having either dog or cat\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "# Model to be trained\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    " \n",
    "# Training only top layers i.e. the layers which we have added in the end\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Compiling the model\n",
    "#model.compile(optimizer= tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4c33ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 5s 862ms/step - loss: 1.1944 - accuracy: 0.5278\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 3s 851ms/step - loss: 1.0454 - accuracy: 0.6111\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 3s 845ms/step - loss: 0.7884 - accuracy: 0.6111\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 3s 842ms/step - loss: 0.9450 - accuracy: 0.4167\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 3s 840ms/step - loss: 0.6788 - accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 3s 838ms/step - loss: 0.7157 - accuracy: 0.4722\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 2s 844ms/step - loss: 0.6880 - accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 3s 871ms/step - loss: 0.7132 - accuracy: 0.3333\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 3s 844ms/step - loss: 0.7186 - accuracy: 0.3333\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 3s 841ms/step - loss: 0.6984 - accuracy: 0.5556\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 3s 849ms/step - loss: 0.7245 - accuracy: 0.4722\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 3s 837ms/step - loss: 0.6768 - accuracy: 0.5833\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-a6340b047c1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#model.fit(train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X,Y,steps_per_epoch=100 // 32,batch_size =12,  epochs=30)\n",
    "#model.fit(train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44be6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier =Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3bee1b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 74, 74, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 37, 37, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 12, 12, 128)       36992     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 6, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 256)               1179904   \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,218,306\n",
      "Trainable params: 1,218,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Classifier.add(Convolution2D(32,3,3,input_shape=(224,224,3),activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "Classifier.add(Convolution2D(128,3,3,activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "Classifier.add(Flatten())\n",
    "Classifier.add(Dense(256, activation='relu'))\n",
    "Classifier.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "Classifier.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "Classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b4c5b023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2197 - accuracy: 0.8889\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3697 - accuracy: 0.9167\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2493 - accuracy: 0.9722\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3415 - accuracy: 0.8889\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2656 - accuracy: 0.8889\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1826 - accuracy: 0.9722\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.2574 - accuracy: 0.9286\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1818 - accuracy: 0.9722\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2861 - accuracy: 0.9167\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3319 - accuracy: 0.8056\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1876 - accuracy: 0.9722\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3031 - accuracy: 0.8889\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1643 - accuracy: 0.9643\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2995 - accuracy: 0.8889\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3332 - accuracy: 0.8611\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2973 - accuracy: 0.9444\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1446 - accuracy: 0.9722\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2174 - accuracy: 0.9444\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2774 - accuracy: 0.9286\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1440 - accuracy: 0.9722\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1651 - accuracy: 0.9722\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6210 - accuracy: 0.8889\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2023 - accuracy: 0.9722\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2921 - accuracy: 0.9167\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1517 - accuracy: 0.9722\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2379 - accuracy: 0.8929\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2507 - accuracy: 0.9167\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1834 - accuracy: 0.9722\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2458 - accuracy: 0.9444\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1329 - accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "#Classifier.fit( X,Y, steps_per_epoch=100/12, batch_size = 12, epochs=12)\n",
    "history = Classifier.fit(X,Y,steps_per_epoch=100 // 32,batch_size =12,  epochs=30)\n",
    "#model.fit(train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7832d9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "07d2d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.58039216, 0.61960784, 0.65882353],\n",
       "         [0.6       , 0.63921569, 0.67843137],\n",
       "         [0.58039216, 0.61960784, 0.65882353],\n",
       "         ...,\n",
       "         [0.78431373, 0.78431373, 0.78431373],\n",
       "         [0.8627451 , 0.8627451 , 0.8627451 ],\n",
       "         [0.86666667, 0.86666667, 0.86666667]],\n",
       "\n",
       "        [[0.59215686, 0.63137255, 0.67058824],\n",
       "         [0.58431373, 0.62352941, 0.6627451 ],\n",
       "         [0.59215686, 0.63137255, 0.67058824],\n",
       "         ...,\n",
       "         [0.72156863, 0.72156863, 0.72156863],\n",
       "         [0.85490196, 0.85490196, 0.85490196],\n",
       "         [0.87058824, 0.87058824, 0.87058824]],\n",
       "\n",
       "        [[0.61960784, 0.65882353, 0.69803922],\n",
       "         [0.56862745, 0.60784314, 0.64705882],\n",
       "         [0.57647059, 0.61568627, 0.65490196],\n",
       "         ...,\n",
       "         [0.83921569, 0.83921569, 0.83921569],\n",
       "         [0.85882353, 0.85882353, 0.85882353],\n",
       "         [0.8627451 , 0.8627451 , 0.8627451 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.88235294, 0.83529412, 0.81176471],\n",
       "         [0.86666667, 0.81960784, 0.79607843],\n",
       "         [0.8745098 , 0.82745098, 0.80392157],\n",
       "         ...,\n",
       "         [0.84313725, 0.8       , 0.78431373],\n",
       "         [0.82352941, 0.78431373, 0.76470588],\n",
       "         [0.80392157, 0.76078431, 0.74509804]],\n",
       "\n",
       "        [[0.85882353, 0.81176471, 0.78823529],\n",
       "         [0.87843137, 0.83137255, 0.80784314],\n",
       "         [0.89411765, 0.84705882, 0.82352941],\n",
       "         ...,\n",
       "         [0.84313725, 0.8       , 0.78039216],\n",
       "         [0.83921569, 0.79607843, 0.78039216],\n",
       "         [0.85098039, 0.80784314, 0.79215686]],\n",
       "\n",
       "        [[0.8627451 , 0.81568627, 0.79215686],\n",
       "         [0.85098039, 0.80392157, 0.78039216],\n",
       "         [0.8627451 , 0.81568627, 0.79607843],\n",
       "         ...,\n",
       "         [0.82745098, 0.78431373, 0.76862745],\n",
       "         [0.80784314, 0.76470588, 0.74901961],\n",
       "         [0.80392157, 0.76078431, 0.74509804]]],\n",
       "\n",
       "\n",
       "       [[[0.9254902 , 0.9372549 , 0.9254902 ],\n",
       "         [0.9372549 , 0.94509804, 0.94117647],\n",
       "         [0.92156863, 0.9254902 , 0.9372549 ],\n",
       "         ...,\n",
       "         [0.98431373, 0.99607843, 0.94117647],\n",
       "         [0.99215686, 0.98039216, 0.93333333],\n",
       "         [1.        , 0.97647059, 0.92941176]],\n",
       "\n",
       "        [[0.69411765, 0.70196078, 0.70588235],\n",
       "         [0.87843137, 0.88235294, 0.89803922],\n",
       "         [0.92941176, 0.93333333, 0.94901961],\n",
       "         ...,\n",
       "         [0.78431373, 0.84705882, 0.78431373],\n",
       "         [0.86666667, 0.90588235, 0.85490196],\n",
       "         [0.94509804, 0.97647059, 0.91372549]],\n",
       "\n",
       "        [[0.52941176, 0.5254902 , 0.56078431],\n",
       "         [0.5254902 , 0.52156863, 0.56078431],\n",
       "         [0.65882353, 0.65882353, 0.68235294],\n",
       "         ...,\n",
       "         [0.37647059, 0.50196078, 0.42745098],\n",
       "         [0.52156863, 0.62745098, 0.55294118],\n",
       "         [0.42745098, 0.51372549, 0.44313725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.96470588, 0.93333333, 0.90588235],\n",
       "         [0.96078431, 0.92941176, 0.90196078],\n",
       "         [0.96470588, 0.93333333, 0.90588235],\n",
       "         ...,\n",
       "         [0.81176471, 0.81176471, 0.78823529],\n",
       "         [0.80392157, 0.80392157, 0.78039216],\n",
       "         [0.78431373, 0.78431373, 0.76078431]],\n",
       "\n",
       "        [[0.98039216, 0.94901961, 0.92156863],\n",
       "         [0.95294118, 0.92156863, 0.89411765],\n",
       "         [0.95294118, 0.92156863, 0.89803922],\n",
       "         ...,\n",
       "         [0.80784314, 0.80784314, 0.78431373],\n",
       "         [0.81960784, 0.81960784, 0.79607843],\n",
       "         [0.80392157, 0.80392157, 0.78039216]],\n",
       "\n",
       "        [[0.97647059, 0.94509804, 0.91764706],\n",
       "         [0.96078431, 0.92941176, 0.90196078],\n",
       "         [0.96078431, 0.92941176, 0.90196078],\n",
       "         ...,\n",
       "         [0.80784314, 0.80784314, 0.78431373],\n",
       "         [0.81960784, 0.81960784, 0.79607843],\n",
       "         [0.80392157, 0.80392157, 0.78039216]]],\n",
       "\n",
       "\n",
       "       [[[0.75686275, 0.78039216, 0.8       ],\n",
       "         [0.78039216, 0.80392157, 0.82352941],\n",
       "         [0.74117647, 0.76470588, 0.78431373],\n",
       "         ...,\n",
       "         [0.39607843, 0.44705882, 0.48627451],\n",
       "         [0.43529412, 0.49803922, 0.53333333],\n",
       "         [0.40392157, 0.47058824, 0.50588235]],\n",
       "\n",
       "        [[0.76862745, 0.79215686, 0.81176471],\n",
       "         [0.74901961, 0.77254902, 0.79215686],\n",
       "         [0.76862745, 0.79215686, 0.81176471],\n",
       "         ...,\n",
       "         [0.47058824, 0.51764706, 0.55686275],\n",
       "         [0.42745098, 0.48627451, 0.52156863],\n",
       "         [0.40392157, 0.47058824, 0.50588235]],\n",
       "\n",
       "        [[0.77254902, 0.79607843, 0.81568627],\n",
       "         [0.74901961, 0.77254902, 0.79215686],\n",
       "         [0.77254902, 0.79607843, 0.81568627],\n",
       "         ...,\n",
       "         [0.49019608, 0.5372549 , 0.57647059],\n",
       "         [0.45098039, 0.50980392, 0.54509804],\n",
       "         [0.42352941, 0.48235294, 0.51764706]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.32941176, 0.3254902 , 0.34117647],\n",
       "         [0.30980392, 0.30588235, 0.31764706],\n",
       "         [0.31372549, 0.32156863, 0.3254902 ],\n",
       "         ...,\n",
       "         [0.22745098, 0.2745098 , 0.2745098 ],\n",
       "         [0.21176471, 0.25098039, 0.25098039],\n",
       "         [0.19215686, 0.23137255, 0.23137255]],\n",
       "\n",
       "        [[0.25098039, 0.24705882, 0.25490196],\n",
       "         [0.22352941, 0.21960784, 0.22745098],\n",
       "         [0.15686275, 0.16470588, 0.16862745],\n",
       "         ...,\n",
       "         [0.36078431, 0.40392157, 0.39607843],\n",
       "         [0.75294118, 0.78431373, 0.78039216],\n",
       "         [0.4       , 0.43137255, 0.42745098]],\n",
       "\n",
       "        [[0.23921569, 0.24313725, 0.23921569],\n",
       "         [0.22352941, 0.22352941, 0.22745098],\n",
       "         [0.15686275, 0.16470588, 0.16862745],\n",
       "         ...,\n",
       "         [0.57647059, 0.61176471, 0.60784314],\n",
       "         [0.74117647, 0.76862745, 0.76862745],\n",
       "         [0.74117647, 0.76470588, 0.76078431]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.72941176, 0.56470588, 0.4745098 ],\n",
       "         [0.72941176, 0.56470588, 0.4745098 ],\n",
       "         [0.73333333, 0.56862745, 0.47843137],\n",
       "         ...,\n",
       "         [0.83921569, 0.67058824, 0.60392157],\n",
       "         [0.83921569, 0.67058824, 0.60392157],\n",
       "         [0.83921569, 0.67058824, 0.60392157]],\n",
       "\n",
       "        [[0.73333333, 0.56862745, 0.47843137],\n",
       "         [0.73333333, 0.56862745, 0.47843137],\n",
       "         [0.7372549 , 0.57254902, 0.48235294],\n",
       "         ...,\n",
       "         [0.84313725, 0.6745098 , 0.60784314],\n",
       "         [0.84313725, 0.6745098 , 0.60784314],\n",
       "         [0.84313725, 0.6745098 , 0.60784314]],\n",
       "\n",
       "        [[0.7372549 , 0.57254902, 0.48235294],\n",
       "         [0.7372549 , 0.57254902, 0.48235294],\n",
       "         [0.74117647, 0.57647059, 0.48627451],\n",
       "         ...,\n",
       "         [0.84705882, 0.67843137, 0.61176471],\n",
       "         [0.84705882, 0.67843137, 0.61176471],\n",
       "         [0.84705882, 0.67843137, 0.61176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.21176471, 0.31764706, 0.41568627],\n",
       "         [0.08235294, 0.23137255, 0.34901961],\n",
       "         [0.15686275, 0.27058824, 0.33333333],\n",
       "         ...,\n",
       "         [0.21176471, 0.19607843, 0.19607843],\n",
       "         [0.21568627, 0.2       , 0.19607843],\n",
       "         [0.21960784, 0.20392157, 0.2       ]],\n",
       "\n",
       "        [[0.15294118, 0.24313725, 0.34901961],\n",
       "         [0.34117647, 0.47058824, 0.58823529],\n",
       "         [0.36470588, 0.45882353, 0.52156863],\n",
       "         ...,\n",
       "         [0.20392157, 0.18823529, 0.18431373],\n",
       "         [0.20392157, 0.18823529, 0.18431373],\n",
       "         [0.21176471, 0.19607843, 0.19215686]],\n",
       "\n",
       "        [[0.19607843, 0.2627451 , 0.38039216],\n",
       "         [0.18431373, 0.29019608, 0.42352941],\n",
       "         [0.05882353, 0.11764706, 0.18823529],\n",
       "         ...,\n",
       "         [0.21568627, 0.2       , 0.19607843],\n",
       "         [0.21176471, 0.19607843, 0.19215686],\n",
       "         [0.20392157, 0.18823529, 0.18431373]]],\n",
       "\n",
       "\n",
       "       [[[0.76862745, 0.6       , 0.53333333],\n",
       "         [0.76862745, 0.6       , 0.53333333],\n",
       "         [0.76862745, 0.6       , 0.53333333],\n",
       "         ...,\n",
       "         [0.71764706, 0.56078431, 0.45098039],\n",
       "         [0.71764706, 0.56078431, 0.45098039],\n",
       "         [0.71764706, 0.56078431, 0.45098039]],\n",
       "\n",
       "        [[0.77254902, 0.60392157, 0.5372549 ],\n",
       "         [0.77254902, 0.60392157, 0.5372549 ],\n",
       "         [0.77254902, 0.60392157, 0.5372549 ],\n",
       "         ...,\n",
       "         [0.72156863, 0.56470588, 0.45490196],\n",
       "         [0.72156863, 0.56470588, 0.45490196],\n",
       "         [0.72156863, 0.56470588, 0.45490196]],\n",
       "\n",
       "        [[0.77647059, 0.60784314, 0.54117647],\n",
       "         [0.77647059, 0.60784314, 0.54117647],\n",
       "         [0.77647059, 0.60784314, 0.54117647],\n",
       "         ...,\n",
       "         [0.7254902 , 0.56862745, 0.45882353],\n",
       "         [0.7254902 , 0.56862745, 0.45882353],\n",
       "         [0.7254902 , 0.56862745, 0.45882353]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.18823529, 0.24313725, 0.31372549],\n",
       "         [0.21568627, 0.29803922, 0.39607843],\n",
       "         [0.2627451 , 0.36470588, 0.47058824],\n",
       "         ...,\n",
       "         [0.16862745, 0.16470588, 0.17254902],\n",
       "         [0.17254902, 0.16862745, 0.18039216],\n",
       "         [0.18431373, 0.18039216, 0.18823529]],\n",
       "\n",
       "        [[0.28627451, 0.34117647, 0.41176471],\n",
       "         [0.25490196, 0.33333333, 0.42745098],\n",
       "         [0.25490196, 0.34901961, 0.45882353],\n",
       "         ...,\n",
       "         [0.16862745, 0.16470588, 0.17254902],\n",
       "         [0.18039216, 0.17647059, 0.18431373],\n",
       "         [0.18431373, 0.18039216, 0.18823529]],\n",
       "\n",
       "        [[0.28627451, 0.33333333, 0.40392157],\n",
       "         [0.23921569, 0.31372549, 0.40784314],\n",
       "         [0.22745098, 0.31764706, 0.42745098],\n",
       "         ...,\n",
       "         [0.17647059, 0.17647059, 0.18431373],\n",
       "         [0.18431373, 0.18039216, 0.18823529],\n",
       "         [0.18039216, 0.17647059, 0.18431373]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 0.96078431, 0.89411765],\n",
       "         [1.        , 0.96078431, 0.89411765],\n",
       "         [1.        , 0.96470588, 0.89803922],\n",
       "         ...,\n",
       "         [0.74509804, 0.64313725, 0.58039216],\n",
       "         [0.74117647, 0.63921569, 0.57647059],\n",
       "         [0.74117647, 0.63921569, 0.57647059]],\n",
       "\n",
       "        [[1.        , 0.96470588, 0.89803922],\n",
       "         [1.        , 0.96470588, 0.89803922],\n",
       "         [1.        , 0.96862745, 0.90196078],\n",
       "         ...,\n",
       "         [0.74901961, 0.64705882, 0.58431373],\n",
       "         [0.74509804, 0.64313725, 0.58039216],\n",
       "         [0.74509804, 0.64313725, 0.58039216]],\n",
       "\n",
       "        [[1.        , 0.96862745, 0.90196078],\n",
       "         [1.        , 0.96862745, 0.90196078],\n",
       "         [1.        , 0.97254902, 0.90588235],\n",
       "         ...,\n",
       "         [0.75294118, 0.65098039, 0.58823529],\n",
       "         [0.74901961, 0.64705882, 0.58431373],\n",
       "         [0.74901961, 0.64705882, 0.58431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.29411765, 0.29019608, 0.29803922],\n",
       "         [0.26666667, 0.2627451 , 0.27058824],\n",
       "         [0.22745098, 0.22352941, 0.23137255],\n",
       "         ...,\n",
       "         [0.03921569, 0.07058824, 0.07058824],\n",
       "         [0.02745098, 0.05490196, 0.05490196],\n",
       "         [0.03137255, 0.0627451 , 0.0627451 ]],\n",
       "\n",
       "        [[0.24705882, 0.24313725, 0.25098039],\n",
       "         [0.2745098 , 0.27058824, 0.27843137],\n",
       "         [0.2745098 , 0.27058824, 0.27843137],\n",
       "         ...,\n",
       "         [0.03137255, 0.0627451 , 0.0627451 ],\n",
       "         [0.01960784, 0.05490196, 0.05490196],\n",
       "         [0.04705882, 0.07843137, 0.07843137]],\n",
       "\n",
       "        [[0.31372549, 0.30980392, 0.31764706],\n",
       "         [0.2627451 , 0.25882353, 0.26666667],\n",
       "         [0.23529412, 0.23137255, 0.23921569],\n",
       "         ...,\n",
       "         [0.03137255, 0.0627451 , 0.0627451 ],\n",
       "         [0.02745098, 0.05882353, 0.05882353],\n",
       "         [0.04705882, 0.07843137, 0.07843137]]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "752891a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Classifier.predict((X))\n",
    "result = np.argmax(res, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "93aa0860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c5b6e0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "de0f6f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[110,   0],\n",
       "       [ 11,  99]], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y, result) \n",
    "confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b577157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
